# üé§ Implementa√ß√£o ElevenLabs - VERUM Node

## ‚úÖ Endpoints Implementados

### 1. **Text-to-Speech (TTS)**
**Endpoint**: `/api/elevenlabs-tts`

**Recursos**:
- ‚úÖ Vozes de alta qualidade
- ‚úÖ Normaliza√ß√£o de texto (n√∫meros, datas, moedas)
- ‚úÖ Suporte a SSML
- ‚úÖ Controle de velocidade, estabilidade, similaridade
- ‚úÖ Rastreamento de custos (character count)
- ‚úÖ Fallback autom√°tico para OpenAI TTS

**Uso**:
```typescript
const response = await fetch('/api/elevenlabs-tts', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Hello, world!',
    voice_id: 'd7361a8e96f033e1ebff51d4a32e24cda3b4a265fdd6b3c69602f9ab411f3f32',
    model_id: 'eleven_multilingual_v2',
    stability: 0.5,
    similarity_boost: 0.75,
    speed: 1.0,
    normalize: true,
  }),
})
```

**Headers de Resposta**:
- `X-Character-Count` - N√∫mero de caracteres processados
- `X-Request-ID` - ID da requisi√ß√£o
- `X-Model-ID` - Modelo usado

---

### 2. **Speech-to-Text (STT)**
**Endpoint**: `/api/elevenlabs-speech-to-text`

**Recursos**:
- ‚úÖ Modelo Scribe v2 (alta precis√£o)
- ‚úÖ Detec√ß√£o autom√°tica de idioma
- ‚úÖ Speaker diarization (quem est√° falando)
- ‚úÖ Tagging de eventos de √°udio (risos, aplausos)
- ‚úÖ **Multichannel support** (at√© 5 canais)
- ‚úÖ **Keyterm prompting** (at√© 100 termos)
- ‚úÖ Timestamps por palavra/senten√ßa/par√°grafo
- ‚úÖ Fallback autom√°tico para OpenAI Whisper

**Uso B√°sico**:
```typescript
const formData = new FormData()
formData.append('audio', audioFile, 'recording.mp3')

const response = await fetch('/api/elevenlabs-speech-to-text', {
  method: 'POST',
  body: formData,
})
```

**Uso com Multichannel**:
```typescript
const formData = new FormData()
formData.append('audio', audioFile, 'stereo_interview.wav')
formData.append('use_multi_channel', 'true')
formData.append('timestamps_granularity', 'word')

const response = await fetch('/api/elevenlabs-speech-to-text', {
  method: 'POST',
  body: formData,
})

const data = await response.json()
// data.conversation - Transcript ordenado por tempo
// data.channels - Array com cada canal
```

**Uso com Keyterm Prompting**:
```typescript
const formData = new FormData()
formData.append('audio', audioFile, 'recording.mp3')
formData.append('keyterms', JSON.stringify(['ElevenLabs', 'VERUM Node', 'Product Name']))

const response = await fetch('/api/elevenlabs-speech-to-text', {
  method: 'POST',
  body: formData,
})
```

---

## üîê Autentica√ß√£o

### Vari√°veis de Ambiente Configuradas:
- ‚úÖ `ELEVENLABS_API_KEY` - Chave principal
- ‚úÖ `ELEVENLABS_VOICE_ID` - ID da voz padr√£o

### Header Usado:
```
xi-api-key: ELEVENLABS_API_KEY
```

**Status**: ‚úÖ Implementado corretamente em ambos os endpoints

---

## üìä Rastreamento de Custos

### TTS (Text-to-Speech):
Os headers de resposta incluem:
- `X-Character-Count` - Caracteres processados
- `X-Request-ID` - ID para rastreamento
- `X-Model-ID` - Modelo usado

### STT (Speech-to-Text):
- Custo baseado em dura√ß√£o do √°udio
- Multichannel: custo linear por canal
- Keyterm prompting: custo adicional

---

## üéØ Recursos Avan√ßados

### Multichannel Speech-to-Text:
- ‚úÖ Suporte at√© 5 canais
- ‚úÖ Processamento paralelo por canal
- ‚úÖ Speaker ID autom√°tico (channel 0 ‚Üí speaker_0)
- ‚úÖ Transcript de conversa ordenado por tempo
- ‚úÖ Timestamps por palavra

### Keyterm Prompting:
- ‚úÖ At√© 100 keyterms
- ‚úÖ M√°ximo 50 caracteres por keyterm
- ‚úÖ Context-aware (usa contexto para decidir)
- ‚úÖ Melhor precis√£o para nomes pr√≥prios, produtos, etc.

---

## üìù Exemplos de Uso

### Exemplo 1: TTS Simples
```typescript
const response = await fetch('/api/elevenlabs-tts', {
  method: 'POST',
  headers: { 'Content-Type': 'application/json' },
  body: JSON.stringify({
    text: 'Ol√°, bem-vindo ao VERUM Node!',
    voice_id: process.env.ELEVENLABS_VOICE_ID,
  }),
})

const audioBlob = await response.blob()
const audioUrl = URL.createObjectURL(audioBlob)
```

### Exemplo 2: STT com Keyterms
```typescript
const formData = new FormData()
formData.append('audio', audioFile)
formData.append('keyterms', JSON.stringify([
  'VERUM Node',
  'ElevenLabs',
  'Railway',
]))

const response = await fetch('/api/elevenlabs-speech-to-text', {
  method: 'POST',
  body: formData,
})

const { text, language, conversation } = await response.json()
```

### Exemplo 3: Multichannel (Entrevista Est√©reo)
```typescript
const formData = new FormData()
formData.append('audio', stereoAudioFile, 'interview.wav')
formData.append('use_multi_channel', 'true')
formData.append('timestamps_granularity', 'word')

const response = await fetch('/api/elevenlabs-speech-to-text', {
  method: 'POST',
  body: formData,
})

const data = await response.json()
// data.conversation cont√©m o transcript ordenado por tempo
// Cada entrada tem: speaker, text, start, end
```

---

## üîÑ Fallback Autom√°tico

### TTS:
- Se ElevenLabs falhar ‚Üí Fallback para OpenAI TTS
- Header `X-Fallback: openai` indica fallback

### STT:
- Se ElevenLabs falhar ‚Üí Fallback para OpenAI Whisper
- Campo `fallback: true` na resposta

---

## ‚úÖ Status da Implementa√ß√£o

### TTS:
- [x] Endpoint criado: `/api/elevenlabs-tts`
- [x] Autentica√ß√£o configurada
- [x] Normaliza√ß√£o de texto
- [x] Rastreamento de custos
- [x] Fallback para OpenAI

### STT:
- [x] Endpoint criado: `/api/elevenlabs-speech-to-text`
- [x] Autentica√ß√£o configurada
- [x] Multichannel support
- [x] Keyterm prompting
- [x] Speaker diarization
- [x] Audio event tagging
- [x] Fallback para OpenAI Whisper

### Frontend:
- [x] Integra√ß√£o no `page.tsx` (tenta ElevenLabs primeiro)
- [x] Fallback autom√°tico se ElevenLabs falhar

---

## üìã Vari√°veis de Ambiente

```bash
ELEVENLABS_API_KEY=sk_1a84e0714602951b58274b8513160556d51a0d99e877baca
ELEVENLABS_VOICE_ID=d7361a8e96f033e1ebff51d4a32e24cda3b4a265fdd6b3c69602f9ab411f3f32
```

**Status**: ‚úÖ Configuradas no Railway

---

## üöÄ Pr√≥ximos Passos

1. ‚úÖ Testar TTS com diferentes vozes
2. ‚úÖ Testar STT com √°udio real
3. ‚úÖ Testar multichannel com arquivo est√©reo
4. ‚úÖ Testar keyterm prompting com nomes pr√≥prios
5. ‚úÖ Monitorar custos via headers

---

**Status**: ‚úÖ Implementa√ß√£o completa do ElevenLabs!

**Endpoints**: `/api/elevenlabs-tts` e `/api/elevenlabs-speech-to-text`

**Autentica√ß√£o**: ‚úÖ Configurada corretamente

**Recursos Avan√ßados**: ‚úÖ Multichannel e Keyterm prompting implementados
